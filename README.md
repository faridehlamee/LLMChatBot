# LLM ChatBot Project

A complete AI chatbot solution with local LLM support and Android app integration.

## Project Structure

```
LLMChatBot/
â”œâ”€â”€ backend/                 # Python FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI application
â”‚   â”‚   â”œâ”€â”€ chatbot.py     # Chatbot logic
â”‚   â”‚   â”œâ”€â”€ llm_client.py  # Local LLM integration
â”‚   â”‚   â””â”€â”€ models.py      # Pydantic models
â”‚   â”œâ”€â”€ static/            # Static files for web UI
â”‚   â”œâ”€â”€ templates/         # HTML templates
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ android/               # Android app (to be created)
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ README.md
```

## Features

- ğŸ¤– AI-powered chatbot with local LLM support
- ğŸŒ REST API for Android app integration
- ğŸ’» Web interface for testing
- ğŸ“± Android app (planned)
- ğŸ”’ Privacy-focused (runs locally)

## Setup Instructions

### 1. Install Local LLM (Ollama)

Download and install Ollama from: https://ollama.ai/

```bash
# Install a model (e.g., Llama 2)
ollama pull llama2
```

### 2. Setup Python Backend

```bash
cd backend
pip install -r requirements.txt
python -m uvicorn app.main:app --reload
```

### 3. Access the Application

- Web Interface: http://localhost:8000
- API Documentation: http://localhost:8000/docs

## API Endpoints

- `POST /api/chat` - Send message to chatbot
- `GET /api/health` - Health check
- `GET /` - Web interface

## Android App Integration

The Android app will communicate with the backend via REST API calls to `/api/chat` endpoint.

## Development Status

- [x] Project structure
- [x] Backend API
- [x] Local LLM integration
- [x] Web interface
- [ ] Android app development
- [ ] Testing and optimization
