# Environment configuration for LLM ChatBot

# LLM Provider Selection
LLM_PROVIDER=ollama

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# Gemini Configuration (for when Ollama is not available)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=True

# Chatbot Configuration
MAX_CONVERSATION_HISTORY=10
RESPONSE_TIMEOUT=30
